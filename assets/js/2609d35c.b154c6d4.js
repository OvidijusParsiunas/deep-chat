"use strict";(self.webpackChunkwebsite=self.webpackChunkwebsite||[]).push([[1285],{94507:(e,n,s)=>{s.r(n),s.d(n,{assets:()=>m,contentTitle:()=>p,default:()=>f,frontMatter:()=>x,metadata:()=>g,toc:()=>j});var r=s(74848),i=s(28453),a=s(26813),t=s(82496),l=s(24033),o=s(50363),c=s(15781),d=s(78478),h=s(19365),u=s(11470);const x={sidebar_position:2},p="HuggingFace",g={id:"docs/directConnection/HuggingFace",title:"HuggingFace",description:"Properties used to connect to Hugging Face API.",source:"@site/docs/docs/directConnection/HuggingFace.mdx",sourceDirName:"docs/directConnection",slug:"/docs/directConnection/HuggingFace",permalink:"/docs/directConnection/HuggingFace",draft:!1,unlisted:!1,editUrl:"https://github.com/OvidijusParsiunas/deep-chat/tree/main/website/docs/docs/directConnection/HuggingFace.mdx",tags:[],version:"current",sidebarPosition:2,frontMatter:{sidebar_position:2},sidebar:"docs",previous:{title:"OpenAI Realtime",permalink:"/docs/directConnection/OpenAI/OpenAIRealtime"},next:{title:"StabilityAI",permalink:"/docs/directConnection/StabilityAI"}},m={},j=[{value:"<code>huggingFace</code>",id:"huggingFace",level:3},{value:"Service Types",id:"service-types",level:2},{value:"<code>Conversation</code>",id:"Conversation",level:3},{value:"Example",id:"example",level:4},{value:"<code>TextGeneration</code>",id:"TextGeneration",level:3},{value:"Example",id:"example-1",level:4},{value:"<code>Summarization</code>",id:"Summarization",level:3},{value:"Example",id:"example-2",level:4},{value:"<code>Translation</code>",id:"Translation",level:3},{value:"Example",id:"example-3",level:4},{value:"<code>FillMask</code>",id:"FillMask",level:3},{value:"Example",id:"example-4",level:4},{value:"<code>QuestionAnswer</code>",id:"QuestionAnswer",level:3},{value:"Example (Ask about labrador looks)",id:"example-ask-about-labrador-looks",level:4},{value:"<code>AudioSpeechRecognition</code>",id:"AudioSpeechRecognition",level:3},{value:"Example",id:"example-5",level:4},{value:"<code>AudioClassification</code>",id:"AudioClassification",level:3},{value:"Example",id:"example-6",level:4},{value:"<code>ImageClassification</code>",id:"ImageClassification",level:3},{value:"Example",id:"example-7",level:4}];function b(e){const n={a:"a",code:"code",em:"em",h1:"h1",h2:"h2",h3:"h3",h4:"h4",header:"header",li:"li",p:"p",pre:"pre",ul:"ul",...(0,i.R)(),...e.components};return(0,r.jsxs)(r.Fragment,{children:[(0,r.jsx)(n.header,{children:(0,r.jsx)(n.h1,{id:"huggingface",children:"HuggingFace"})}),"\n","\n",(0,r.jsxs)(n.h1,{id:"hugging-face",children:[(0,r.jsx)("img",{src:a.A,width:"60",style:{float:"left",marginRight:"5px"}}),(0,r.jsx)("span",{className:"direct-service-title",children:"Hugging Face"})]}),"\n",(0,r.jsxs)(n.p,{children:["Properties used to connect to ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/index",children:"Hugging Face API"}),"."]}),"\n",(0,r.jsx)(n.h3,{id:"huggingFace",children:(0,r.jsx)(n.code,{children:"huggingFace"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: { ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#Conversation",children:(0,r.jsx)(n.code,{children:"conversation?: Conversation"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#TextGeneration",children:(0,r.jsx)(n.code,{children:"textGeneration?: TextGeneration"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#Summarization",children:(0,r.jsx)(n.code,{children:"summarization?: Summarization"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#Translation",children:(0,r.jsx)(n.code,{children:"translation?: Translation"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#FillMask",children:(0,r.jsx)(n.code,{children:"fillMask?: FillMask"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#QuestionAnswer",children:(0,r.jsx)(n.code,{children:"questionAnswer?: QuestionAnswer"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#AudioSpeechRecognition",children:(0,r.jsx)(n.code,{children:"audioSpeechRecognition?: AudioSpeechRecognition"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#AudioClassification",children:(0,r.jsx)(n.code,{children:"audioClassification?: AudioClassification"})}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.a,{href:"#ImageClassification",children:(0,r.jsx)(n.code,{children:"imageClassification?: ImageClassification"})})," ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:"{conversation: true}"})]}),"\n"]}),"\n"]}),"\n","\n",(0,r.jsx)(d.A,{children:()=>s(61886).readdAutoNavShadowToggle()}),"\n",(0,r.jsx)(n.h2,{id:"service-types",children:"Service Types"}),"\n",(0,r.jsx)(n.h3,{id:"Conversation",children:(0,r.jsx)(n.code,{children:"Conversation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"model?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"parameters?:"})," { ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"min_length?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"max_length?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_k?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_p?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"temperature?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"repetition_penalty?: string"}),"}, ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"options?:"})," {",(0,r.jsx)(n.code,{children:"use_cache?: boolean"}),"} ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "facebook/blenderbot-400M-distill", options: {use_cache: true}}'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#conversational-task",children:(0,r.jsx)(n.code,{children:"Conversational"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"min_length"})," is the minimum length in tokens of the output summary. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"max_length"})," is the maximum length in tokens of the output summary. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_k"})," defines the top tokens considered within the sample operation to create new text. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_p"})," is a float to define the tokens that are within the sample operation of text generation. Add tokens in the sample for more probable to least probable until the sum of the probabilities is greater than top * p. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"temperature"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") temperature of the sampling operation. 1 means regular sampling, ",(0,r.jsx)(n.em,{children:"0"})," means always take the highest score, ",(0,r.jsx)(n.em,{children:"100.0"})," is getting closer to uniform probability. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"repetition_penalty"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") that controls where a token is used more within generation the more it is penalized to not be picked in successive generation passes. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"use_cache"})," is used to speed up requests by using the inference API cache."]}),"\n",(0,r.jsx)(n.h4,{id:"example",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",conversation:{model:"facebook/blenderbot-400M-distill",parameters:{temperature:1}}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{conversation:{model:"facebook/blenderbot-400M-distill",parameters:{temperature:1}}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "conversation": {"model": "facebook/blenderbot-400M-distill", "parameters": {"temperature": 1}}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "conversation": {"model": "facebook/blenderbot-400M-distill", "parameters": {"temperature": 1}}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"TextGeneration",children:(0,r.jsx)(n.code,{children:"TextGeneration"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"model?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"parameters?:"})," { ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_k?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_p?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"temperature?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"repetition_penalty?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"max_new_tokens?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"do_sample?: boolean"}),"}, ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"options?:"})," {",(0,r.jsx)(n.code,{children:"use_cache?: boolean"}),"} ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "gpt2", options: {use_cache: true}}'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#text-generation-task",children:(0,r.jsx)(n.code,{children:"Text Generation"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_k"})," defines the top tokens considered within the sample operation to create new text. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_p"})," is a float to define the tokens that are within the sample operation of text generation. Add tokens in the sample for more probable to least probable until the sum of the probabilities is greater than top * p. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"temperature"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") temperature of the sampling operation. 1 means regular sampling, ",(0,r.jsx)(n.em,{children:"0"})," means always take the highest score, ",(0,r.jsx)(n.em,{children:"100.0"})," is getting closer to uniform probability. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"repetition_penalty"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") that controls where a token is used more within generation the more it is penalized to not be picked in successive generation passes. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"max_new_tokens"})," is an integer (ranging from ",(0,r.jsx)(n.em,{children:"0"})," to ",(0,r.jsx)(n.em,{children:"250"}),") amount of new tokens to be generated by the response. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"do_sample"})," controls whether or not to use sampling. If ",(0,r.jsx)(n.code,{children:"false"})," it uses greedy decoding sampling. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"use_cache"})," is used to speed up requests by using the inference API cache."]}),"\n",(0,r.jsx)(n.h4,{id:"example-1",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",textGeneration:{model:"gpt2",parameters:{temperature:1}}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{textGeneration:{model:"gpt2",parameters:{temperature:1}}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "textGeneration": {"model": "gpt2", "parameters": {"temperature": 1}}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "textGeneration": {"model": "gpt2", "parameters": {"temperature": 1}}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"Summarization",children:(0,r.jsx)(n.code,{children:"Summarization"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"model?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"parameters?:"})," { ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"min_length?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"max_length?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_k?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"top_p?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"temperature?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"repetition_penalty?: string"}),"}, ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"options?:"})," {",(0,r.jsx)(n.code,{children:"use_cache?: boolean"}),"} ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "facebook/bart-large-cnn", options: {use_cache: true}}'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#summarization-task",children:(0,r.jsx)(n.code,{children:"Summarization"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"min_length"})," is the minimum length in tokens of the output summary. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"max_length"})," is the maximum length in tokens of the output summary. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_k"})," defines the top tokens considered within the sample operation to create new text. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"top_p"})," is a float to define the tokens that are within the sample operation of text generation. Add tokens in the sample for more probable to least probable until the sum of the probabilities is greater than top * p. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"temperature"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") temperature of the sampling operation. 1 means regular sampling, ",(0,r.jsx)(n.em,{children:"0"})," means always take the highest score, ",(0,r.jsx)(n.em,{children:"100.0"})," is getting closer to uniform probability. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"repetition_penalty"})," is a float (ranging from ",(0,r.jsx)(n.em,{children:"0.0"})," to ",(0,r.jsx)(n.em,{children:"100.0"}),") that controls where a token is used more within generation the more it is penalized to not be picked in successive generation passes. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"use_cache"})," is used to speed up requests by using the inference API cache."]}),"\n",(0,r.jsx)(n.h4,{id:"example-2",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",summarization:{model:"facebook/bart-large-cnn",parameters:{temperature:1}}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{summarization:{model:"facebook/bart-large-cnn",parameters:{temperature:1}}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "summarization": {"model": "facebook/bart-large-cnn", "parameters": {"temperature": 1}}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "summarization": {"model": "facebook/bart-large-cnn", "parameters": {"temperature": 1}}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"Translation",children:(0,r.jsx)(n.code,{children:"Translation"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"model?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"options?:"})," {",(0,r.jsx)(n.code,{children:"use_cache?: boolean"}),"} ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "Helsinki-NLP/opus-tatoeba-en-ja", options: {use_cache: true}}'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#translation-task",children:(0,r.jsx)(n.code,{children:"Translation"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"use_cache"})," is used to speed up requests by using the inference API cache."]}),"\n",(0,r.jsx)(n.h4,{id:"example-3",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",translation:{model:"Helsinki-NLP/opus-tatoeba-en-ja"}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{translation:{model:"Helsinki-NLP/opus-tatoeba-en-ja"}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "translation": {"model": "Helsinki-NLP/opus-tatoeba-en-ja"}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "translation": {"model": "Helsinki-NLP/opus-tatoeba-en-ja"}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"FillMask",children:(0,r.jsx)(n.code,{children:"FillMask"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"model?: string"}),", ",(0,r.jsx)("br",{}),"\n\xa0\xa0\xa0\xa0 ",(0,r.jsx)(n.code,{children:"options?:"})," {",(0,r.jsx)(n.code,{children:"use_cache?: boolean"}),"} ",(0,r.jsx)("br",{}),"\n}"]}),"\n"]}),"\n",(0,r.jsxs)(n.li,{children:["\n",(0,r.jsxs)(n.p,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "bert-base-uncased", options: {use_cache: true}}'})]}),"\n"]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#fill-mask-task",children:(0,r.jsx)(n.code,{children:"Fill Mask"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"use_cache"})," is used to speed up requests by using the inference API cache."]}),"\n",(0,r.jsx)(n.h4,{id:"example-4",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",fillMask:{model:"bert-base-uncased"}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{fillMask:{model:"bert-base-uncased"}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "fillMask": {"model": "bert-base-uncased"}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "fillMask": {"model": "bert-base-uncased"}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"QuestionAnswer",children:(0,r.jsx)(n.code,{children:"QuestionAnswer"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)(n.code,{children:"context: string"}),", ",(0,r.jsx)(n.code,{children:"model?: string"}),"}"]}),"\n",(0,r.jsxs)(n.li,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "bert-large-uncased-whole-word-masking-finetuned-squad"}'})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#question-answering-task",children:(0,r.jsx)(n.code,{children:"Question Answer"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"context"})," is a string containing details that AI can use to answer the given questions. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h4,{id:"example-ask-about-labrador-looks",children:"Example (Ask about labrador looks)"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",questionAnswer:{model:"bert-large-uncased-whole-word-masking-finetuned-squad",context:"Labrador retrievers are easily recognized by their broad head, drop ears and large, expressive eyes. Two trademarks of the Lab are the thick but fairly short double coat, which is very water repellent, and the well known otter tail. The tail is thick and sturdy and comes off the topline almost straight."}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{questionAnswer:{model:"bert-large-uncased-whole-word-masking-finetuned-squad",context:"Labrador retrievers are easily recognized by their broad head, drop ears and large, expressive eyes. Two trademarks of the Lab are the thick but fairly short double coat, which is very water repellent, and the well known otter tail. The tail is thick and sturdy and comes off the topline almost straight."}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "questionAnswer": {\n        "model": "bert-large-uncased-whole-word-masking-finetuned-squad",\n        "context": "Labrador retrievers are easily recognized by their broad head, drop ears and large, expressive eyes. Two trademarks of the Lab are the thick but fairly short double coat, which is very water repellent, and the well known otter tail. The tail is thick and sturdy and comes off the topline almost straight."\n        }\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "questionAnswer": {\n        "model": "bert-large-uncased-whole-word-masking-finetuned-squad",\n        "context": "Labrador retrievers are easily recognized by their broad head, drop ears and large, expressive eyes. Two trademarks of the Lab are the thick but fairly short double coat, which is very water repellent, and the well known otter tail. The tail is thick and sturdy and comes off the topline almost straight."\n        }\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"AudioSpeechRecognition",children:(0,r.jsx)(n.code,{children:"AudioSpeechRecognition"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)(n.code,{children:"model?: string"}),"}"]}),"\n",(0,r.jsxs)(n.li,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "facebook/wav2vec2-large-960h-lv60-self"}'})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#automatic-speech-recognition-task",children:(0,r.jsx)(n.code,{children:"Audio Speech Recognition"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h4,{id:"example-5",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",audioSpeechRecognition:{model:"facebook/wav2vec2-large-960h-lv60-self"}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{audioSpeechRecognition:{model:"facebook/wav2vec2-large-960h-lv60-self"}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "huggingFace": {"model": "facebook/wav2vec2-large-960h-lv60-self"}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "huggingFace": {"model": "facebook/wav2vec2-large-960h-lv60-self"}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"AudioClassification",children:(0,r.jsx)(n.code,{children:"AudioClassification"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)(n.code,{children:"model?: string"}),"}"]}),"\n",(0,r.jsxs)(n.li,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"}'})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#audio-classification-task",children:(0,r.jsx)(n.code,{children:"Audio Classification"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h4,{id:"example-6",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",audioClassification:{model:"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{audioSpeechRecognition:{model:"ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "audioSpeechRecognition": {"model": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "audioSpeechRecognition": {"model": "ehcalabres/wav2vec2-lg-xlsr-en-speech-emotion-recognition"}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{}),"\n",(0,r.jsx)(n.h3,{id:"ImageClassification",children:(0,r.jsx)(n.code,{children:"ImageClassification"})}),"\n",(0,r.jsxs)(n.ul,{children:["\n",(0,r.jsxs)(n.li,{children:["Type: ",(0,r.jsx)(n.code,{children:"true"})," | {",(0,r.jsx)(n.code,{children:"model?: string"}),"}"]}),"\n",(0,r.jsxs)(n.li,{children:["Default: ",(0,r.jsx)(n.em,{children:'{model: "google/vit-base-patch16-224"}'})]}),"\n"]}),"\n",(0,r.jsxs)(n.p,{children:["Connect to Hugging Face ",(0,r.jsx)(n.a,{href:"https://huggingface.co/docs/api-inference/detailed_parameters#image-classification-task",children:(0,r.jsx)(n.code,{children:"Image Classification"})})," API. ",(0,r.jsx)("br",{}),"\n",(0,r.jsx)(n.code,{children:"model"})," is the name of the model used for the task. ",(0,r.jsx)("br",{})]}),"\n",(0,r.jsx)(n.h4,{id:"example-7",children:"Example"}),"\n",(0,r.jsxs)(t.A,{children:[(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{key:"placeholder key",imageClassification:{model:"google/vit-base-patch16-224"}}}})}),(0,r.jsx)(l.A,{children:(0,r.jsx)(o.A,{style:{borderRadius:"8px"},directConnection:{huggingFace:{imageClassification:{model:"google/vit-base-patch16-224"}}}})})]}),"\n",(0,r.jsxs)(u.A,{children:[(0,r.jsx)(h.A,{value:"js",label:"Sample code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "imageClassification": {"model": "google/vit-base-patch16-224"}\n    }\n  }\'\n></deep-chat>\n'})})}),(0,r.jsx)(h.A,{value:"py",label:"Full code",children:(0,r.jsx)(n.pre,{children:(0,r.jsx)(n.code,{className:"language-html",children:'\x3c!-- This example is for Vanilla JS and should be tailored to your framework (see Examples) --\x3e\n\n<deep-chat\n  directConnection=\'{\n    "huggingFace": {\n      "key": "placeholder key",\n      "imageClassification": {"model": "google/vit-base-patch16-224"}\n    }\n  }\'\n  style="border-radius: 8px"\n></deep-chat>\n'})})})]}),"\n",(0,r.jsx)(c.A,{})]})}function f(e={}){const{wrapper:n}={...(0,i.R)(),...e.components};return n?(0,r.jsx)(n,{...e,children:(0,r.jsx)(b,{...e})}):b(e)}},19365:(e,n,s)=>{s.d(n,{A:()=>t});s(96540);var r=s(34164);const i={tabItem:"tabItem_Ymn6"};var a=s(74848);function t(e){let{children:n,hidden:s,className:t}=e;return(0,a.jsx)("div",{role:"tabpanel",className:(0,r.A)(i.tabItem,t),hidden:s,children:n})}},11470:(e,n,s)=>{s.d(n,{A:()=>v});var r=s(96540),i=s(34164),a=s(23104),t=s(56347),l=s(205),o=s(57485),c=s(31682),d=s(70679);function h(e){return r.Children.toArray(e).filter((e=>"\n"!==e)).map((e=>{if(!e||(0,r.isValidElement)(e)&&function(e){const{props:n}=e;return!!n&&"object"==typeof n&&"value"in n}(e))return e;throw new Error(`Docusaurus error: Bad <Tabs> child <${"string"==typeof e.type?e.type:e.type.name}>: all children of the <Tabs> component should be <TabItem>, and every <TabItem> should have a unique "value" prop.`)}))?.filter(Boolean)??[]}function u(e){const{values:n,children:s}=e;return(0,r.useMemo)((()=>{const e=n??function(e){return h(e).map((e=>{let{props:{value:n,label:s,attributes:r,default:i}}=e;return{value:n,label:s,attributes:r,default:i}}))}(s);return function(e){const n=(0,c.XI)(e,((e,n)=>e.value===n.value));if(n.length>0)throw new Error(`Docusaurus error: Duplicate values "${n.map((e=>e.value)).join(", ")}" found in <Tabs>. Every value needs to be unique.`)}(e),e}),[n,s])}function x(e){let{value:n,tabValues:s}=e;return s.some((e=>e.value===n))}function p(e){let{queryString:n=!1,groupId:s}=e;const i=(0,t.W6)(),a=function(e){let{queryString:n=!1,groupId:s}=e;if("string"==typeof n)return n;if(!1===n)return null;if(!0===n&&!s)throw new Error('Docusaurus error: The <Tabs> component groupId prop is required if queryString=true, because this value is used as the search param name. You can also provide an explicit value such as queryString="my-search-param".');return s??null}({queryString:n,groupId:s});return[(0,o.aZ)(a),(0,r.useCallback)((e=>{if(!a)return;const n=new URLSearchParams(i.location.search);n.set(a,e),i.replace({...i.location,search:n.toString()})}),[a,i])]}function g(e){const{defaultValue:n,queryString:s=!1,groupId:i}=e,a=u(e),[t,o]=(0,r.useState)((()=>function(e){let{defaultValue:n,tabValues:s}=e;if(0===s.length)throw new Error("Docusaurus error: the <Tabs> component requires at least one <TabItem> children component");if(n){if(!x({value:n,tabValues:s}))throw new Error(`Docusaurus error: The <Tabs> has a defaultValue "${n}" but none of its children has the corresponding value. Available values are: ${s.map((e=>e.value)).join(", ")}. If you intend to show no default tab, use defaultValue={null} instead.`);return n}const r=s.find((e=>e.default))??s[0];if(!r)throw new Error("Unexpected error: 0 tabValues");return r.value}({defaultValue:n,tabValues:a}))),[c,h]=p({queryString:s,groupId:i}),[g,m]=function(e){let{groupId:n}=e;const s=function(e){return e?`docusaurus.tab.${e}`:null}(n),[i,a]=(0,d.Dv)(s);return[i,(0,r.useCallback)((e=>{s&&a.set(e)}),[s,a])]}({groupId:i}),j=(()=>{const e=c??g;return x({value:e,tabValues:a})?e:null})();(0,l.A)((()=>{j&&o(j)}),[j]);return{selectedValue:t,selectValue:(0,r.useCallback)((e=>{if(!x({value:e,tabValues:a}))throw new Error(`Can't select invalid tab value=${e}`);o(e),h(e),m(e)}),[h,m,a]),tabValues:a}}var m=s(92303);const j={tabList:"tabList__CuJ",tabItem:"tabItem_LNqP"};var b=s(74848);function f(e){let{className:n,block:s,selectedValue:r,selectValue:t,tabValues:l}=e;const o=[],{blockElementScrollPositionUntilNextRender:c}=(0,a.a_)(),d=e=>{const n=e.currentTarget,s=o.indexOf(n),i=l[s].value;i!==r&&(c(n),t(i))},h=e=>{let n=null;switch(e.key){case"Enter":d(e);break;case"ArrowRight":{const s=o.indexOf(e.currentTarget)+1;n=o[s]??o[0];break}case"ArrowLeft":{const s=o.indexOf(e.currentTarget)-1;n=o[s]??o[o.length-1];break}}n?.focus()};return(0,b.jsx)("ul",{role:"tablist","aria-orientation":"horizontal",className:(0,i.A)("tabs",{"tabs--block":s},n),children:l.map((e=>{let{value:n,label:s,attributes:a}=e;return(0,b.jsx)("li",{role:"tab",tabIndex:r===n?0:-1,"aria-selected":r===n,ref:e=>o.push(e),onKeyDown:h,onClick:d,...a,className:(0,i.A)("tabs__item",j.tabItem,a?.className,{"tabs__item--active":r===n}),children:s??n},n)}))})}function y(e){let{lazy:n,children:s,selectedValue:a}=e;const t=(Array.isArray(s)?s:[s]).filter(Boolean);if(n){const e=t.find((e=>e.props.value===a));return e?(0,r.cloneElement)(e,{className:(0,i.A)("margin-top--md",e.props.className)}):null}return(0,b.jsx)("div",{className:"margin-top--md",children:t.map(((e,n)=>(0,r.cloneElement)(e,{key:n,hidden:e.props.value!==a})))})}function k(e){const n=g(e);return(0,b.jsxs)("div",{className:(0,i.A)("tabs-container",j.tabList),children:[(0,b.jsx)(f,{...n,...e}),(0,b.jsx)(y,{...n,...e})]})}function v(e){const n=(0,m.A)();return(0,b.jsx)(k,{...e,children:h(e.children)},String(n))}},15781:(e,n,s)=>{s.d(n,{A:()=>i});s(96540);var r=s(74848);function i(){return(0,r.jsx)("div",{style:{height:"1px"}})}},61886:(e,n,s)=>{function r(e){window.scrollY>0?e.style.boxShadow="0 1px 2px 0 rgb(0 0 0 / 10%)":e.style.boxShadow="unset"}function i(){setTimeout((()=>{window.removeEventListener("scroll",window.toggleNavOnScroll);const e=document.getElementsByClassName("navbar--fixed-top");if(e[0]){const n=e[0];r(n),window.toggleNavOnScroll=r.bind(this,n),window.addEventListener("scroll",window.toggleNavOnScroll)}}),2)}function a(){setTimeout((()=>{const e=document.querySelectorAll(".homepage > body > #__docusaurus > nav")?.[0];try{e.classList.add("fade-in")}catch(n){console.error(n),console.log("element was not rendered in time - use MutationObserver")}}),2)}s.r(n),s.d(n,{fadeIn:()=>a,readdAutoNavShadowToggle:()=>i})},24033:(e,n,s)=>{s.d(n,{A:()=>a,q:()=>i});s(96540);var r=s(74848);function i(e){return e?.children[0]?.children[0]}function a(e){let{children:n,minHeight:s,innerDisplay:i}=e;return(0,r.jsx)("div",{className:"documentation-example-container",style:{minHeight:`${s||400}px`},children:(0,r.jsx)("div",{style:{display:i||"block"},children:n})})}},82496:(e,n,s)=>{s.d(n,{A:()=>a});var r=s(96540),i=s(74848);function a(e){let{children:n}=e;const[s,a]=r.useState(!0);return(0,i.jsxs)("div",{children:[s&&n[0],!s&&n[1],(0,i.jsx)("div",{className:"component-key-toggle-button-container",children:(0,i.jsxs)("button",{className:"documentation-button component-key-toggle-button",onClick:()=>a(!s),children:[s&&"Insert test key",!s&&"Use placeholder key"]})})]})}},50363:(e,n,s)=>{s.d(n,{A:()=>a});var r=s(78478),i=(s(96540),s(74848));function a(e){return(0,i.jsx)(r.A,{children:()=>{const n=s(78152).DeepChat;return(0,i.jsx)(n,{...e,children:e.children})}})}},26813:(e,n,s)=>{s.d(n,{A:()=>r});const r=s.p+"assets/images/huggingFaceLogo-fc1ff0c8a51b1066702d41f83250bd9d.png"},28453:(e,n,s)=>{s.d(n,{R:()=>t,x:()=>l});var r=s(96540);const i={},a=r.createContext(i);function t(e){const n=r.useContext(a);return r.useMemo((function(){return"function"==typeof e?e(n):{...n,...e}}),[n,e])}function l(e){let n;return n=e.disableParentContext?"function"==typeof e.components?e.components(i):e.components||i:t(e.components),r.createElement(a.Provider,{value:n},e.children)}}}]);